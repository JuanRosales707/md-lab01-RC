{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPn7HFS5go1aXmv2chY/mF3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanRosales707/md-lab01-RC/blob/main/LAB_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmCHqnc1XZJ3",
        "outputId": "49827eae-1190-4dd7-bd2b-9e8e8900c2e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.4.26)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "breast_cancer_wisconsin_original = fetch_ucirepo(id=15)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = breast_cancer_wisconsin_original.data.features\n",
        "y = breast_cancer_wisconsin_original.data.targets\n",
        "\n",
        "# metadata\n",
        "print(breast_cancer_wisconsin_original.metadata)\n",
        "\n",
        "# variable information\n",
        "print(breast_cancer_wisconsin_original.variables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZdcKblmaVVd",
        "outputId": "bf187d97-cc64-4259-dec5-adf2851aa382"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 15, 'name': 'Breast Cancer Wisconsin (Original)', 'repository_url': 'https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original', 'data_url': 'https://archive.ics.uci.edu/static/public/15/data.csv', 'abstract': 'Original Wisconsin Breast Cancer Database', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 699, 'num_features': 9, 'feature_types': ['Integer'], 'demographics': [], 'target_col': ['Class'], 'index_col': ['Sample_code_number'], 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1990, 'last_updated': 'Sun Mar 10 2024', 'dataset_doi': '10.24432/C5HP4Z', 'creators': ['WIlliam Wolberg'], 'intro_paper': None, 'additional_info': {'summary': \"Samples arrive periodically as Dr. Wolberg reports his clinical cases. The database therefore reflects this chronological grouping of the data. This grouping information appears immediately below, having been removed from the data itself:\\r\\n\\r\\nGroup 1: 367 instances (January 1989)\\r\\nGroup 2:  70 instances (October 1989)\\r\\nGroup 3:  31 instances (February 1990)\\r\\nGroup 4:  17 instances (April 1990)\\r\\nGroup 5:  48 instances (August 1990)\\r\\nGroup 6:  49 instances (Updated January 1991)\\r\\nGroup 7:  31 instances (June 1991)\\r\\nGroup 8:  86 instances (November 1991)\\r\\n-----------------------------------------\\r\\nTotal:   699 points (as of the donated datbase on 15 July 1992)\\r\\n\\r\\nNote that the results summarized above in Past Usage refer to a dataset of size 369, while Group 1 has only 367 instances.  This is because it originally contained 369 instances; 2 were removed.  The following statements summarizes changes to the original Group 1's set of data:\\r\\n\\r\\n#####  Group 1 : 367 points: 200B 167M (January 1989)\\r\\n\\r\\n#####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805\\r\\n\\r\\n#####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record\\r\\n#####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial\\r\\n#####                  : Changed 0 to 1 in field 6 of sample 1219406\\r\\n#####                  : Changed 0 to 1 in field 8 of following sample:\\r\\n#####                  : 1182404,2,3,1,1,1,2,0,1,1,1\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1. Sample code number:            id number\\r\\n2. Clump Thickness:               1 - 10\\r\\n3. Uniformity of Cell Size:       1 - 10\\r\\n4. Uniformity of Cell Shape:      1 - 10\\r\\n5. Marginal Adhesion:             1 - 10\\r\\n6. Single Epithelial Cell Size:   1 - 10\\r\\n7. Bare Nuclei:                   1 - 10\\r\\n8. Bland Chromatin:               1 - 10\\r\\n9. Normal Nucleoli:               1 - 10\\r\\n10. Mitoses:                       1 - 10\\r\\n11. Class:                        (2 for benign, 4 for malignant)', 'citation': 'This breast cancer databases was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg.  If you publish results when using this database, then please include this information in your acknowledgements.  Also, please cite one or more of:\\n1. O. L. Mangasarian and W. H. Wolberg: \"Cancer diagnosis via linear programming\", SIAM News, Volume 23, Number 5, September 1990, pp 1 & 18.\\n2. William H. Wolberg and O.L. Mangasarian: \"Multisurface method of pattern separation for medical diagnosis applied to breast cytology\", Proceedings of the National Academy of Sciences, U.S.A., Volume 87, December 1990, pp 9193-9196.\\n3. O. L. Mangasarian, R. Setiono, and W.H. Wolberg: \"Pattern recognition via linear programming: Theory and application to medical diagnosis\", in: \"Large-scale numerical optimization\", Thomas F. Coleman and Yuying Li, editors, SIAM Publications, Philadelphia 1990, pp 22-30.\\n4. K. P. Bennett & O. L. Mangasarian: \"Robust linear programming discrimination of two linearly inseparable sets\", Optimization Methods and Software 1, 1992, 23-34 (Gordon & Breach Science Publishers).'}}\n",
            "                           name     role         type demographic  \\\n",
            "0            Sample_code_number       ID  Categorical        None   \n",
            "1               Clump_thickness  Feature      Integer        None   \n",
            "2       Uniformity_of_cell_size  Feature      Integer        None   \n",
            "3      Uniformity_of_cell_shape  Feature      Integer        None   \n",
            "4             Marginal_adhesion  Feature      Integer        None   \n",
            "5   Single_epithelial_cell_size  Feature      Integer        None   \n",
            "6                   Bare_nuclei  Feature      Integer        None   \n",
            "7               Bland_chromatin  Feature      Integer        None   \n",
            "8               Normal_nucleoli  Feature      Integer        None   \n",
            "9                       Mitoses  Feature      Integer        None   \n",
            "10                        Class   Target       Binary        None   \n",
            "\n",
            "                  description units missing_values  \n",
            "0                        None  None             no  \n",
            "1                        None  None             no  \n",
            "2                        None  None             no  \n",
            "3                        None  None             no  \n",
            "4                        None  None             no  \n",
            "5                        None  None             no  \n",
            "6                        None  None            yes  \n",
            "7                        None  None             no  \n",
            "8                        None  None             no  \n",
            "9                        None  None             no  \n",
            "10  2 = benign, 4 = malignant  None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **a. Calcule el information value (IV), tanto para el grupo de variable numéricas como categóricas y  excluya las que tenga un poder predictivo débil o menor. Además, separe la variable de  clasificación del resto de variables para luego obtener los datos de entrenamiento y prueba,  tomando de este último el 25% de datos.**"
      ],
      "metadata": {
        "id": "gvM4AX6obvuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Cargar dataset desde URL\n",
        "link = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\"\n",
        "columnas = [\"ID\", \"Clump_Thickness\", \"Uniformity_Cell_Size\", \"Uniformity_Cell_Shape\",\n",
        "            \"Marginal_Adhesion\", \"Single_Epithelial_Cell_Size\", \"Bare_Nuclei\",\n",
        "            \"Bland_Chromatin\", \"Normal_Nucleoli\", \"Mitoses\", \"Class\"]\n",
        "data = pd.read_csv(link, names=columnas)\n",
        "\n",
        "# Limpieza de datos\n",
        "data = data.replace(\"?\", np.nan)\n",
        "data[\"Bare_Nuclei\"] = pd.to_numeric(data[\"Bare_Nuclei\"])\n",
        "data = data.dropna().drop(columns=[\"ID\"])\n",
        "data[\"Class\"] = data[\"Class\"].map({2: 0, 4: 1})  # 0 = benigno, 1 = maligno\n",
        "\n",
        "# Función para calcular Information Value (IV)\n",
        "def obtener_iv(df, variable, objetivo, num_bins=5):\n",
        "    temp = df[[variable, objetivo]].copy()\n",
        "    if not pd.api.types.is_object_dtype(temp[variable]):\n",
        "        temp[variable] = pd.qcut(temp[variable], q=num_bins, duplicates='drop')\n",
        "    tabla = temp.groupby(variable)[objetivo].agg(['count', 'sum'])\n",
        "    tabla.columns = ['Total', 'Positivos']\n",
        "    tabla['Negativos'] = tabla['Total'] - tabla['Positivos']\n",
        "    tabla['Perc_Pos'] = tabla['Positivos'] / tabla['Positivos'].sum()\n",
        "    tabla['Perc_Neg'] = tabla['Negativos'] / tabla['Negativos'].sum()\n",
        "    tabla['WoE'] = np.log(tabla['Perc_Pos'] / tabla['Perc_Neg']).replace([np.inf, -np.inf], 0)\n",
        "    tabla['IV'] = (tabla['Perc_Pos'] - tabla['Perc_Neg']) * tabla['WoE']\n",
        "    return tabla['IV'].sum()\n",
        "\n",
        "# Calcular IV de todas las variables\n",
        "iv_resultados = {}\n",
        "for feature in data.columns.drop('Class'):\n",
        "    iv_resultados[feature] = round(obtener_iv(data, feature, 'Class'), 4)\n",
        "\n",
        "# Seleccionar variables con IV >= 0.1\n",
        "iv_tabla = pd.DataFrame.from_dict(iv_resultados, orient='index', columns=['IV']).sort_values('IV', ascending=False)\n",
        "iv_tabla_filtrada = iv_tabla.query('IV >= 0.1')\n",
        "variables_finales = iv_tabla_filtrada.index.tolist()\n",
        "\n",
        "# Definir X (predictoras) e y (objetivo)\n",
        "X = data[variables_finales]\n",
        "y = data[\"Class\"]\n",
        "\n",
        "# Dividir conjunto en entrenamiento (75%) y prueba (25%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "# Mostrar resumen\n",
        "print(\"Variables seleccionadas:\", variables_finales)\n",
        "print(f\"Entrenamiento: {X_train.shape} | Prueba: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq_FQhBkfytJ",
        "outputId": "abd5b32c-7ba3-406b-f4b2-585813d02d7c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-7d5f8c3f6258>:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  tabla = temp.groupby(variable)[objetivo].agg(['count', 'sum'])\n",
            "<ipython-input-18-7d5f8c3f6258>:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  tabla = temp.groupby(variable)[objetivo].agg(['count', 'sum'])\n",
            "<ipython-input-18-7d5f8c3f6258>:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  tabla = temp.groupby(variable)[objetivo].agg(['count', 'sum'])\n",
            "<ipython-input-18-7d5f8c3f6258>:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  tabla = temp.groupby(variable)[objetivo].agg(['count', 'sum'])\n",
            "<ipython-input-18-7d5f8c3f6258>:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  tabla = temp.groupby(variable)[objetivo].agg(['count', 'sum'])\n",
            "<ipython-input-18-7d5f8c3f6258>:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  tabla = temp.groupby(variable)[objetivo].agg(['count', 'sum'])\n",
            "<ipython-input-18-7d5f8c3f6258>:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  tabla = temp.groupby(variable)[objetivo].agg(['count', 'sum'])\n",
            "<ipython-input-18-7d5f8c3f6258>:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  tabla = temp.groupby(variable)[objetivo].agg(['count', 'sum'])\n",
            "<ipython-input-18-7d5f8c3f6258>:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  tabla = temp.groupby(variable)[objetivo].agg(['count', 'sum'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variables seleccionadas: ['Uniformity_Cell_Size', 'Bare_Nuclei', 'Uniformity_Cell_Shape', 'Bland_Chromatin', 'Single_Epithelial_Cell_Size', 'Clump_Thickness', 'Marginal_Adhesion', 'Normal_Nucleoli']\n",
            "Entrenamiento: (512, 8) | Prueba: (171, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b. Genere el modelo de regresión logística y evalúe la exclusión de variables mediante la  significancia de los coeficientes. Además, calcule las métricas de clasificación que se  implementaron en la parte práctica e interprete sus resultados más importantes.**"
      ],
      "metadata": {
        "id": "UPa-Fy9uhyYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Agregar constante para incluir el intercepto en el modelo de statsmodels\n",
        "X_train_constant = sm.add_constant(X_train)\n",
        "\n",
        "# Ajustar el modelo de regresión logística con statsmodels\n",
        "modelo_logit = sm.Logit(y_train, X_train_constant).fit()\n",
        "\n",
        "# Mostrar resumen del modelo\n",
        "print(modelo_logit.summary())\n",
        "\n",
        "# Filtrar las variables significativas (p-value <= 0.05)\n",
        "p_valores = modelo_logit.pvalues.drop(\"const\")\n",
        "variables_significativas = p_valores[p_valores <= 0.05].index.tolist()\n",
        "\n",
        "# Crear nuevos conjuntos de entrenamiento y prueba con las variables significativas\n",
        "X_train_significativas = X_train[variables_significativas]\n",
        "X_test_significativas = X_test[variables_significativas]\n",
        "\n",
        "# Entrenar el modelo usando scikit-learn\n",
        "modelo_clf = LogisticRegression()\n",
        "modelo_clf.fit(X_train_significativas, y_train)\n",
        "\n",
        "# Predecir las clases y probabilidades\n",
        "predicciones = modelo_clf.predict(X_test_significativas)\n",
        "probabilidades = modelo_clf.predict_proba(X_test_significativas)[:, 1]\n",
        "\n",
        "# Mostrar el reporte de clasificación\n",
        "print(\"\\n=== Reporte de Clasificación ===\")\n",
        "print(classification_report(y_test, predicciones))\n",
        "\n",
        "# Imprimir la matriz de confusión\n",
        "print(\"Matriz de Confusión:\")\n",
        "print(confusion_matrix(y_test, predicciones))\n",
        "\n",
        "# Calcular y mostrar AUC (Área bajo la curva ROC)\n",
        "print(f\"AUC: {roc_auc_score(y_test, probabilidades):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM3Ec_fKhp8Z",
        "outputId": "1e78aff3-3a9d-473a-8159-608aedb985df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.063072\n",
            "         Iterations 10\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                  Class   No. Observations:                  512\n",
            "Model:                          Logit   Df Residuals:                      503\n",
            "Method:                           MLE   Df Model:                            8\n",
            "Date:                Sat, 03 May 2025   Pseudo R-squ.:                  0.9025\n",
            "Time:                        00:26:10   Log-Likelihood:                -32.293\n",
            "converged:                       True   LL-Null:                       -331.37\n",
            "Covariance Type:            nonrobust   LLR p-value:                5.843e-124\n",
            "===============================================================================================\n",
            "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------------------\n",
            "const                         -10.3115      1.440     -7.160      0.000     -13.134      -7.489\n",
            "Uniformity_Cell_Size            0.2634      0.316      0.833      0.405      -0.356       0.883\n",
            "Bare_Nuclei                     0.6777      0.154      4.395      0.000       0.376       0.980\n",
            "Uniformity_Cell_Shape           0.2464      0.329      0.749      0.454      -0.399       0.891\n",
            "Bland_Chromatin                 0.1538      0.208      0.740      0.459      -0.253       0.561\n",
            "Single_Epithelial_Cell_Size     0.1944      0.198      0.983      0.326      -0.193       0.582\n",
            "Clump_Thickness                 0.6639      0.177      3.756      0.000       0.317       1.010\n",
            "Marginal_Adhesion               0.2808      0.159      1.763      0.078      -0.031       0.593\n",
            "Normal_Nucleoli                 0.1401      0.148      0.947      0.343      -0.150       0.430\n",
            "===============================================================================================\n",
            "\n",
            "Possibly complete quasi-separation: A fraction 0.12 of observations can be\n",
            "perfectly predicted. This might indicate that there is complete\n",
            "quasi-separation. In this case some parameters will not be identified.\n",
            "\n",
            "=== Reporte de Clasificación ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.95       111\n",
            "           1       0.91      0.88      0.90        60\n",
            "\n",
            "    accuracy                           0.93       171\n",
            "   macro avg       0.93      0.92      0.92       171\n",
            "weighted avg       0.93      0.93      0.93       171\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[106   5]\n",
            " [  7  53]]\n",
            "AUC: 0.9770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **c. Genere el modelo SVM, calcule sus métricas de clasificación y compárelas con las del modelo  de regresión logística para ver si hubo o no mejoras.**"
      ],
      "metadata": {
        "id": "B-D0Ct13iVoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Importar librerías necesarias\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Paso 2: Dividir los datos (70% entrenamiento, 30% prueba)\n",
        "X_train_sig, X_test_sig, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Paso 3: Estandarización\n",
        "scaler = StandardScaler()\n",
        "X_train_sig_scaled = scaler.fit_transform(X_train_sig)\n",
        "X_test_sig_scaled = scaler.transform(X_test_sig)\n",
        "\n",
        "# Paso 4: Crear y ajustar el modelo SVM (lineal con probabilidades)\n",
        "svm_clf = SVC(kernel='linear', probability=True)\n",
        "svm_clf.fit(X_train_sig_scaled, y_train)\n",
        "\n",
        "# Paso 5: Predicciones\n",
        "y_pred_svm = svm_clf.predict(X_test_sig_scaled)\n",
        "y_prob_svm = svm_clf.predict_proba(X_test_sig_scaled)[:, 1]\n",
        "\n",
        "# Paso 6: Métricas\n",
        "print(\"\\n=== Reporte de Clasificación SVM ===\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "print(\"Matriz de Confusión SVM:\")\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n",
        "print(f\"AUC (SVM): {roc_auc_score(y_test, y_prob_svm):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMEJlKKslmyJ",
        "outputId": "d652f905-dfa7-4b6a-a4e0-a172f7955c70"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Reporte de Clasificación SVM ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       127\n",
            "           1       0.97      0.94      0.95        78\n",
            "\n",
            "    accuracy                           0.97       205\n",
            "   macro avg       0.97      0.96      0.96       205\n",
            "weighted avg       0.97      0.97      0.97       205\n",
            "\n",
            "Matriz de Confusión SVM:\n",
            "[[125   2]\n",
            " [  5  73]]\n",
            "AUC (SVM): 0.9963\n"
          ]
        }
      ]
    }
  ]
}